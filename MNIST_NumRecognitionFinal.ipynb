{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Parameters\n",
    "TRAIN_BATCH_SIZE = 50\n",
    "TEST_BATCH_SIZE = 50\n",
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "# Convert class labels from scalars to one-hot vectors \n",
    "# 2 => [0 0 1 0 0 0 0 0 0 0]\n",
    "# 5 => [0 0 0 0 0 1 0 0 0 0]\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "# Serve data by batches\n",
    "def next_batch(batch_size):    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(27000,784)\n",
      "validation_images(5000,784)\n",
      "test_images(10000,784)\n"
     ]
    }
   ],
   "source": [
    "# read input train data from csv file\n",
    "train_data = pd.read_csv('./input/train.csv')\n",
    "\n",
    "images = train_data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# Normalize from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "image_size = images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "# For labels\n",
    "labels_flat = train_data[[0]].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))\n",
    "\n",
    "# read test data from CSV file \n",
    "test_images = pd.read_csv('./input/test.csv').values\n",
    "\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABZRJREFUeJzt3T9LlW8cx/HfiVIC1xYFcRQKHFojCMnNxT9rThX0BNoa\nIqK9pWdQhA2KODQ4GZiL0trQEjgFQUOY5Pk9gvt7zOP54/m8Xuv33Nd9L2+v4fI+p9Vut/8D8lwZ\n9AMAgyF+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CHW1z/fz74TQe62zfMjOD6HED6HED6HED6HED6HE\nD6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HE\nD6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HED6HE\nD6HED6HED6HED6HED6HED6HED6HED6HED6HED6GuDvoBLsrp6Wk5f/fuXTn/8uVLOf/27Vvj7P37\n9+W1DMba2lrjbHFxsbx2eXn5oh9n6Nj5IZT4IZT4IZT4IZT4IZT4IZT4IVSr3W738349u9nx8XE5\nX1hYKOdfv34t5xMTE//8TBdlfn6+nN++fbtPT9Jf379/L+fPnz8/99qPHj0q52/evDn32kOgdZYP\n2fkhlPghlPghlPghlPghlPghlPgh1Mi8zz8+Pl7Onz17Vs6vXKn/Dt67d++fn4nuHB4elvNuzvmx\n80Ms8UMo8UMo8UMo8UMo8UMo8UOokTnn76TTO/EMn+q3EuienR9CiR9CiR9CiR9CiR9CiR9CiR9C\njcz39nP5HB0dlfObN2+W858/f5bz6enpxtnW1lZ57a1bt8r5kPO9/UAz8UMo8UMo8UMo8UMo8UOo\nmFd6GT6vX78u552O8jp5/Phx4+ySH+VdCDs/hBI/hBI/hBI/hBI/hBI/hBI/hHLOT0/9/v27cbaz\ns9PV2jMzM+X8wYMHXa0/6uz8EEr8EEr8EEr8EEr8EEr8EEr8EMo5Pz11//79xtn+/n557bVr18r5\nkydPyvnU1FQ5T2fnh1Dih1Dih1Dih1Dih1Dih1Dih1B+opuu/Pjxo5xPTk42zk5OTspr5+bmyvnB\nwUE5D+YnuoFm4odQ4odQ4odQ4odQ4odQ4odQ3uenKy9fviznnc7yK8vLy+e+ls7s/BBK/BBK/BBK\n/BBK/BBK/BDKK72Utre3y/nS0lI5//PnT+Pszp075bUfPnwo5zdu3CjnwbzSCzQTP4QSP4QSP4QS\nP4QSP4QSP4Ryzk/p7t275Xx3d7ecVz+z3el/CObn58s5jZzzA83ED6HED6HED6HED6HED6HED6F8\ndXe4Fy9elPO9vb2u1n/79m3jzDn+YNn5IZT4IZT4IZT4IZT4IZT4IZT4IZT3+Ufc379/y3mn787/\n/PlzOR8bGyvnv379apxV7/rTFe/zA83ED6HED6HED6HED6HED6G80jsCTk5OGmebm5vltZ2O8iYm\nJsr5+vp6OXecN7zs/BBK/BBK/BBK/BBK/BBK/BBK/BDKOf8I+PTpU+NsdXW1q7VXVlbK+cLCQlfr\nMzh2fgglfgglfgglfgglfgglfgglfgjlnP8SOD4+LuevXr3q2b2np6d7tjaDZeeHUOKHUOKHUOKH\nUOKHUOKHUOKHUM75L4G9vb1y/vHjx3Ov/fDhw3L+9OnTc6/NcLPzQyjxQyjxQyjxQyjxQyjxQyjx\nQyjn/JfAxsZGz9aem5sr59evX+/ZvRksOz+EEj+EEj+EEj+EEj+EEj+EctQXbnZ2dtCPwIDY+SGU\n+CGU+CGU+CGU+CGU+CGU+CFUq91u9/N+fb0ZhGqd5UN2fgglfgglfgglfgglfgglfgglfgjV7/f5\nz3T+CPSenR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9C\niR9CiR9CiR9CiR9CiR9CiR9C/Q8eya9RCy8tlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25b1c2eccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display image\n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "\n",
    "# output image     \n",
    "display(images[1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 0\n",
      "training_accuracy / validation_accuracy => 0.84 / 0.84 for step 100\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "x_range = []\n",
    "\n",
    "for i in range(2000):\n",
    "  batch_images,batch_labels = next_batch(TRAIN_BATCH_SIZE)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch_images, y_: batch_labels, keep_prob: 1.0})\n",
    "    if(VALIDATION_SIZE):\n",
    "        validation_accuracy = accuracy.eval(feed_dict={ x: validation_images[0:TEST_BATCH_SIZE], \n",
    "                                                            y_: validation_labels[0:TEST_BATCH_SIZE], \n",
    "                                                            keep_prob: 1.0})                                  \n",
    "        print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "    else: \n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    x_range.append(i)\n",
    "  train_step.run(feed_dict={x: batch_images, y_: batch_labels, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check final accuracy on validation set separated from input train data set\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "if(VALIDATION_SIZE > 0):\n",
    "    validation_accuracy = accuracy.eval(feed_dict={x: validation_images, \n",
    "                                                   y_: validation_labels,\n",
    "                                                   keep_prob: 1.0})\n",
    "\n",
    "    plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "    plt.plot(x_range, validation_accuracies,'-g', label='Validation')\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()\n",
    "    \n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows change in training and validation accuracies as the training steps progresses. Here for generating the graph only 2000 iterations are run where as to generate csv output file 20000 iteration are run in GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = tf.argmax(y_conv, 1)\n",
    "EVAL_BATCH_SIZE = 50\n",
    "# generating predicted labels using batches\n",
    "predicted_lables = np.zeros(test_images.shape[0])\n",
    "for i in range(0,test_images.shape[0]//EVAL_BATCH_SIZE):\n",
    "    predicted_lables[i*EVAL_BATCH_SIZE : (i+1)*EVAL_BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*EVAL_BATCH_SIZE : (i+1)*EVAL_BATCH_SIZE], keep_prob: 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write output - save results to csv file\n",
    "np.savetxt('ChaitanyaSubmissionFinal.csv', \n",
    "           np.c_[range(1,len(test_images)+1),predicted_lables], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '', \n",
    "           fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
